---
title: "week4-2 A realistic view of AI 人工智能的现实观点"
categories: "AI For Everyone"
tags:
  - AI
  - DL
  - ML
comments: true
date: 2019-03-04 11:27:20
---

![4-2-0.png](https://upload-images.jianshu.io/upload_images/910914-38b51b6785227eb9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

人工智能正在对社会和许多人的生活产生巨大影响。

所以，对于我们所有人做出好的决定，重要的是我们要有一个现实的人工智能观，既不太乐观，也不太悲观。

这就是我的意思。

你有没有读过金发姑娘和三只熊的故事。

<!--more-->

![4-2-1.png](https://upload-images.jianshu.io/upload_images/910914-01114e0ce992ef02.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![4-2-2.png](https://upload-images.jianshu.io/upload_images/910914-bbb6d5ed232e6c3e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![4-2-3.png](https://upload-images.jianshu.io/upload_images/910914-bc35e377ccc4b1b1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

故事的一部分是，一碗粥不应该太热也不能太冷，abed既不应该太坚硬也不应该太软。

我认为我们需要一个类似的人工智能的Gililocks规则，我认为重要的是我们对AI技术能做什么或不能做什么既不过于乐观也不过于悲观。

例如，我们不应该对AI技术过于乐观，对人工智能技术持不切实际的看法可能会让人们认为很快就会出现感知或超级智能，人工，一般智能，我们应该投入大量资源来防御反邪恶的杀手机器人。

我认为做一些研究来思考如果人工智能在某一天有所改变，那么遥远的未来会是什么样子并没有错。

做基础研究确实不是问题，但我们不应过度分配资源，以防止实际上不会长期存在的危险。

也许几十年，也许几百年。

我认为对感知，超级情报，人工一般情报的不必要的恐惧正在分散人们对真实问题的注意力，并且在社会的某些部分也引起了对艾滋病的不必要的恐惧。

另一方面，我们也不想对AI进行操作。

人工智能的极端悲观主义观点是人工智能无法做到的一切。

有些东西是不能做的，所以，另一个AI冬天来了。

AI冬季这个术语指的是当人工智能被过度炒作时，以及当人们发现人工智能无法完成他们想到的所有事情时，会发生几次剧情。

这导致了人工智能的丧失和人工投资的减少。

人工智能现在和几十年前的早期冬天之间的一个区别是，今天的人工智能正在创造巨大的经济价值。

我们也看到了一条令人惊讶的明确路径，它继续在多个行业中创造更多价值。

因此，这两件事的结合确保AI在可预见的未来将继续增长。

尽管如此，AI也无法做到。

我对金发姑娘的故事并没有过于乐观或过于悲观，而是了解到中间的事情恰到好处。

我认为我们现在意识到，人工智能无法做到。

事实上，有一个不可能但它会改变行业和社会。

当你和AI的朋友交谈时，我希望你也告诉他们关于AI的这个Goldilocksrule，所以，他们也可以有更真实的人工智能观。

AI存在许多局限性。

您之前已经看到了一些性能限制。

例如，给予少量数据，纯粹的AI可能无法完全自动化呼叫中心，并对任何客户提供非常灵活的响应。

但AI也有其他限制。

AI的局限性之一是可解释性很难，许多高性能的AI系统都是黑盒子。

这意味着它工作得很好，但AI不知道如何解释它为什么会这样做。

这是一个例子。

假设您有一个AI系统，请查看此X射线图像，以诊断患者是否有任何错误。

在这个例子中，一个原始的例子，A​​I系统说它认为患者有右侧气胸。

这意味着右肺塌陷了。

但我们怎么知道AI是否正确，你怎么知道你是否应该相信AI系统的诊断。

在制作AI系统方面做了很多工作。

在这个例子中，热图是AI告诉我们它正在查看图像的哪些部分以便进行诊断。

因为它显然是基于右肺的诊断，实际上是右肺的一些关键特征。

看到这张图片可能会让人更有信心AI正在做出合理的诊断。

现在，公平地说，人类也不太善于解释我们如何自己做出决定。

例如，你在过去几周的视频中已经看过这个咖啡杯，但你怎么知道这是一个咖啡杯？

人们如何看待这个并说，这是一个咖啡杯？

你知道有一些你可以指出的东西，有一个液体的空间，它有一个手柄。

但是我们人类不善于解释，我们如何看待它并决定它是什么。

但是因为人工智能是一个相对较新的东西，缺乏可解释性有时候会被接受。

此外，有时如果AI系统不能正常工作，那么它解释自身的能力也会帮助我们弄清楚如何进入并让AI系统更好地工作。

因此，可解释性是主要的开放研究领域之一。

很多研究人员都在努力。

我在实践中看到的是，当AI团队想要部署某些东西时，AI团队必须经常能够提出足够好的解释来使系统能够进行部署。

因此，可解释性是温床，它通常并非不可能但我们确实需要更好的工具来帮助AI系统解释自己。

AI有一些其他的限制。

作为一个社会，我们不希望基于他们的种族歧视基于性别的个人，我们希望人们得到公平对待。

但是，当人工智能系统被输入的数据不能反映这些值时，人工智能就会变成偏见，或者可以学会区别对待某些人。

人工智能社区正在努力工作，并在这些问题上取得了很好的进展，但我们还远未完成，而且还有很多工作要做。

您将在下一个视频中了解有关偏向AI的更多信息，以及如何确保您使用的AI系统偏向性较小的一些想法。

最后，许多人工智能系统正在制定经济上重要的决策，而一些人工智能系统则是开放的对抗性攻击，如果其他人故意愚弄你的人工智能系统。

因此，根据您的应用程序，确保您不会对AI系统上的这些类型的攻击持开放态度可能很重要。

人工智能和歧视，人工智能和偏见以及对人工智能的对抗性攻击问题对你作为潜在的建设者和人工智能以及社会用户都很重要。

在下一个视频中，让我们更深入地探讨人工智能和偏见问题。

讲师：[Andrew Ng](https://www.coursera.org/instructor/andrewng)
课程：<https://www.coursera.org/learn/ai-for-everyone>
